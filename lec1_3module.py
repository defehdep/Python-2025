# Машинное обучение

# ML решает следующую задачу
# Требуется подогнать заданный набор точек с данными подогнать под соответсвтующую функцию,
# (отображает входа на выход), которая улавливает важные сигналы в данных и игнорирует помехи
# Затем нужно убедиться, что на новых данных функция работает хорошо



# Обучение с учителем (Supervised lerning) - моделирует отношение между признаками и метками.
# Такие модели служат для предсказания меток на основе обучающих данных (маркированных).
# После построения модели можно использовать её для присвоения меток новым, ранее неизвестным данным.

# - Задачи классификации (метки дискретные)
# - Задачи регрессии (метки/результат - непроерывные величины)



# Обучение без учителя (Unsupervisec learning) - моделирует признаки без меток.
# Такие модели служат для выявления структуры немаркированных данных 

# - Задачи кластеризации (выделяет отдельные группы данных среди всех данных)
# - Задача понижения размерности (поиск более сжатого представления данных)



# Существуе такой вид обучения, как частичное обучение (semi-supervised lerning).
# Метки неполные (не все данные промаркированы)



# Методы, относящиеся к обучению с подкреплением (reinforcement learning).
# Система обучения улучшает свои характеристики на основе взаимодействия (обратной связи со средой)
# При этом взаимодествии система получает сигналы (функции наград), которые несут в себе информацию,
# насколько хорошо система решила задачу (с точки зрения среды). Пока итоговая награда не станет максимальной


import seaborn as sns

iris = sns.load_dataset('iris')

# print(iris.head())
# print(type(iris))
# print(iris.columns)
# print(iris.values)
# print(iris.index)

# Строки - отдельные объекты - образцы (sample)
# Столбцы - признаки - соответствуют конкретным наблюдениям
# Матрицы признаков (features matrix) размер [число образцов x число признаков]
# Целевой массив (массив меток) (targets) - обычно одномерный массив [1 x число бразцов] -
# данные, которые мы хотим предсказать на основе имеющихся у нас данных

# Зависимые (метки) и независимые переменные (признаки)



# Типичный процесс построения системы машинного обучения

# 1. Предварительная обработка
# - На вход поступает необработанные данные и метки
# - Происходит выбор признаков, если надо, признаки масштабируются
# - Понижение размерности (оставить только необходимые признаки)  (Чем меньше данные, тем проще модель)
# - Выборка образцов
# - На выход поступает набор данных (обычно делится на 2 группы): обучающий (обучение) и тестовый набор (демонстрация результата)

# 2. Обучение модели
# - Выбор модели
# - Перекрестная проверка
# - Построение метрик эффективности модели
# - Оптимизация гиперпараметров. Гиперпараметры - парметры, которые получаются не из данных, а являются настраеваемыми характеристиками модели 

# 3. Оценка и формирование конечной модели

# 4. Прогнозирование (использование/применениие модели)


# SciKit-learn - библиотека

# 1. Выбираем класс модели
# 2. Устанавливаем гиперпараметры модели
# 3. Создаем матрицу признаков и целевой массив
# 4. Обучение модели fit() - метод экземпляра
# 5. Применяем модель к новым данным
# - predict() (с учителем)
# - transform() (без учителя)



# Обученние с учителем: Линейная регрессия

# Простая линейная регрессия

# y = ax + b

import matplotlib.pyplot as plt 
import numpy as np
import numpy.random as rnd

rnd.seed(1)

# I

x = 10 * rnd.rand(50)
y = 2 * x + -1 + rnd.randn(50)

plt.scatter(x, y)

# II
# 1. Выбираем класс модели

from sklearn.linear_model import LinearRegression

# 2. Устанавливаем гиперпараметры модели

model = LinearRegression(fit_intercept=True)

# 3. Создаем матрицу признаков и целевой массив

# print(x.shape)
# print(y.shape)
X = x[:, np.newaxis]

# 4. Обучение модели fit() - метод экземпляра

model.fit(X, y)

print(model.coef_[0])
print(model.intercept_)

X_ = np.linspace(0,10,30)
Y_ = model.coef_[0] * X_ + model.intercept_

plt.plot(X_, Y_)

# 5. Применяем модель к новым данным
# - с учителем -> predict()

xfit = np.linspace(0,10,5)
yfit = model.predict(xfit[:, np.newaxis])

plt.scatter(xfit, yfit)

plt.show()